#!/usr/bin/env python3
"""
æ»‘å‹•çª—å£æ‰‹èªè­˜åˆ¥è…³æœ¬

âš ï¸  æ¨¡å‹ç‰ˆæœ¬ï¼šv3.0 - Deep Improvementsï¼ˆæ·±åº¦æ”¹é€²ç‰ˆï¼‰

ğŸ¯ v3.0 é—œéµæ”¹é€²ï¼š
1. å¤šå°ºåº¦æ± åŒ–ï¼šGlobalMaxPool + GlobalAvgPool ä¸¦è¯
2. MaxNorm ç´„æŸï¼šé˜²æ­¢æ¥µç«¯ logitsï¼ˆEmbedding=3.0, Logits=1.5ï¼‰
3. Focal Loss (Î³=2.0)ï¼šé™ä½ç°¡å–®æ¨£æœ¬æ¬Šé‡
4. Temperature Scaling (T=1.5)ï¼šæ ¡æº–ä¿¡å¿ƒåº¦åˆ†ä½ˆ
5. Mixup (Î±=0.2)ï¼šbatch ç´šåˆ¥æ¨£æœ¬æ··åˆï¼ˆè¨“ç·´æ™‚ï¼‰
6. Label Smoothing (Îµ=0.1)ï¼šè»ŸåŒ– one-hot æ¨™ç±¤

ğŸ“Š é æœŸæ”¹å–„ï¼š
- ä¿¡å¿ƒåº¦ï¼š70-85%ï¼ˆåŸ 98%+ éæ–¼è‡ªä¿¡ï¼‰
- æº–ç¢ºç‡ï¼š92-96%ï¼ˆåŸ 100% è¡¨ç¤ºéæ“¬åˆï¼‰
- Top-1 åˆ° Top-5 æ¦‚ç‡æ›´å¹³æ»‘
- ç›¸ä¼¼æ‰‹å‹¢ï¼ˆå¦‚ teacher/studentï¼‰ä¸å†æ¥µç«¯èª¤åˆ¤

ğŸ”§ æ¨è«–ç‰¹æ€§ï¼š
- æ‰€æœ‰æ”¹é€²åœ¨æ¨è«–æ™‚è‡ªå‹•ç”Ÿæ•ˆ
- BatchNorm/LayerNorm è‡ªå‹•åˆ‡æ›æ¨è«–æ¨¡å¼
- Temperature Scaling å±¤é€æ˜è™•ç†
- ç„¡éœ€ä»£ç¢¼ä¿®æ”¹

åŠŸèƒ½ï¼š
1. è®€å–ä»»æ„é•·åº¦å½±ç‰‡ï¼ˆæœ€çŸ­ 80 å¹€ï¼‰
2. æ»‘å‹•çª—å£æƒæï¼š80 å¹€/çª—å£ï¼Œå¯èª¿æ­¥é•·
3. æ¯å€‹çª—å£ç¨ç«‹æ¨è«–ï¼šTop-5 çµæœ
4. æ™‚é–“è»¸å¯è¦–åŒ–ï¼šå®Œæ•´è¼¸å‡ºæ‰€æœ‰çª—å£çµæœ
5. JSON çµæœä¿å­˜ï¼šä¾¿æ–¼å¾ŒçºŒåˆ†æ
"""

import os
import sys
import cv2
import numpy as np
import torch
from pathlib import Path
from datetime import datetime
import json
import time
from openai import OpenAI

# è¨­ç½® Keras backend ç‚º TensorFlow
os.environ['KERAS_BACKEND'] = 'tensorflow'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
import keras

# å°å…¥æ¨¡çµ„
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent / "feature_extraction"))

from rgb_feature_extraction import RGBFeatureExtractor
from skeleton_feature_extraction import EnhancedSkeletonExtractor


# ==================== è‡ªå®šç¾©å±¤å®šç¾©ï¼ˆè¼‰å…¥æ¨¡å‹éœ€è¦ï¼‰====================
@keras.saving.register_keras_serializable()
class FocalLoss(keras.losses.Loss):
    """Focal Loss"""
    def __init__(self, num_classes=15, gamma=2.0, alpha=None, label_smoothing=0.1, name='focal_loss', **kwargs):
        super().__init__(name=name, **kwargs)
        self.num_classes = num_classes
        self.gamma = gamma
        self.alpha = alpha
        self.label_smoothing = label_smoothing
    def call(self, y_true, y_pred):
        from keras import ops
        if len(ops.shape(y_true)) == 1:
            y_true_one_hot = ops.one_hot(ops.cast(y_true, 'int32'), self.num_classes)
            if self.label_smoothing > 0:
                y_true_one_hot = y_true_one_hot * (1.0 - self.label_smoothing) + self.label_smoothing / self.num_classes
        else:
            y_true_one_hot = y_true
        epsilon = 1e-7
        y_pred = ops.clip(y_pred, epsilon, 1.0 - epsilon)
        cross_entropy = -y_true_one_hot * ops.log(y_pred)
        p_t = ops.sum(y_true_one_hot * y_pred, axis=-1, keepdims=True)
        focal_weight = ops.power(1.0 - p_t, self.gamma)
        focal_cross_entropy = focal_weight * cross_entropy
        if self.alpha is not None:
            alpha_weight = y_true_one_hot * self.alpha
            focal_cross_entropy = alpha_weight * focal_cross_entropy
        return ops.mean(ops.sum(focal_cross_entropy, axis=-1))
    def get_config(self):
        config = super().get_config()
        config.update({'num_classes': self.num_classes, 'gamma': self.gamma, 'alpha': self.alpha, 'label_smoothing': self.label_smoothing})
        return config

@keras.saving.register_keras_serializable()
class MixupAccuracy(keras.metrics.Metric):
    """Mixup Accuracy"""
    def __init__(self, name='mixup_accuracy', **kwargs):
        super().__init__(name=name, **kwargs)
        self.total = self.add_weight(name='total', initializer='zeros')
        self.count = self.add_weight(name='count', initializer='zeros')
    def update_state(self, y_true, y_pred, sample_weight=None):
        from keras import ops
        if len(ops.shape(y_true)) == 1:
            y_true_labels = ops.cast(y_true, 'int32')
        else:
            y_true_labels = ops.argmax(y_true, axis=-1)
        y_pred_labels = ops.argmax(y_pred, axis=-1)
        matches = ops.cast(ops.equal(y_true_labels, y_pred_labels), 'float32')
        self.total.assign_add(ops.sum(matches))
        self.count.assign_add(ops.cast(ops.size(matches), 'float32'))
    def result(self):
        return self.total / self.count
    def reset_state(self):
        self.total.assign(0.0)
        self.count.assign(0.0)

@keras.saving.register_keras_serializable()
class MixupTop3Accuracy(keras.metrics.Metric):
    """Mixup Top-3 Accuracy"""
    def __init__(self, name='mixup_top3_accuracy', **kwargs):
        super().__init__(name=name, **kwargs)
        self.total = self.add_weight(name='total', initializer='zeros')
        self.count = self.add_weight(name='count', initializer='zeros')
    def update_state(self, y_true, y_pred, sample_weight=None):
        from keras import ops
        if len(ops.shape(y_true)) == 1:
            y_true_labels = ops.cast(y_true, 'int32')
        else:
            y_true_labels = ops.argmax(y_true, axis=-1)
        top3_pred = ops.top_k(y_pred, k=3)[1]
        y_true_expanded = ops.expand_dims(y_true_labels, axis=-1)
        matches = ops.any(ops.equal(top3_pred, y_true_expanded), axis=-1)
        matches = ops.cast(matches, 'float32')
        self.total.assign_add(ops.sum(matches))
        self.count.assign_add(ops.cast(ops.size(matches), 'float32'))
    def result(self):
        return self.total / self.count
    def reset_state(self):
        self.total.assign(0.0)
        self.count.assign(0.0)


class SlidingWindowInference:
    """æ»‘å‹•çª—å£æ‰‹èªè­˜åˆ¥å™¨"""
    
    # åƒæ•¸é…ç½®
    WINDOW_SIZE = 80        # æ¯å€‹çª—å£ 80 å¹€ï¼ˆç´„ 2.67 ç§’ @ 30fpsï¼‰
    TARGET_FPS = 30         # ç›®æ¨™å¹€ç‡
    TARGET_WIDTH = 224      # ç›®æ¨™å¯¬åº¦
    TARGET_HEIGHT = 224     # ç›®æ¨™é«˜åº¦
    
    def __init__(self, model_path, label_map_path, device='mps', stride=80, openai_api_key=None, progress_callback=None):
        """
        åˆå§‹åŒ–æ»‘å‹•çª—å£è­˜åˆ¥å™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾‘
            label_map_path: æ¨™ç±¤æ˜ å°„è·¯å¾‘
            device: è¨­å‚™é¡å‹ï¼ˆç”¨æ–¼ç‰¹å¾µæå–å™¨ï¼Œæ¨è«–å¼·åˆ¶ä½¿ç”¨ CPUï¼‰
            stride: æ»‘å‹•æ­¥é•·ï¼ˆå¹€æ•¸ï¼‰
                   - 80 å¹€ï¼ˆé è¨­ï¼‰ï¼šç„¡é‡ç–Šï¼Œæœ€å¿«ï¼Œé©åˆå¿«é€Ÿæƒæ
                   - 60 å¹€ï¼š25% é‡ç–Šï¼Œå¹³è¡¡
                   - 40 å¹€ï¼š50% é‡ç–Šï¼Œæ›´å¯†é›†æª¢æ¸¬
            openai_api_key: OpenAI API é‡‘é‘°ï¼ˆç”¨æ–¼å¥å­é‡çµ„ï¼‰
            progress_callback: é€²åº¦å›èª¿å‡½æ•¸ï¼Œåƒæ•¸ç‚º (current, total, message)
        
        æ³¨æ„ï¼šè¨“ç·´æ•¸æ“šå¹³å‡å–®è©é•·åº¦ç‚º 88 å¹€ï¼ˆ3.1 ç§’ï¼‰
        """
        self.device = device
        self.stride = stride
        self.openai_client = None
        self.progress_callback = progress_callback
        
        # åˆå§‹åŒ– OpenAI
        if openai_api_key:
            try:
                self.openai_client = OpenAI(api_key=openai_api_key)
                print("âœ… OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—: {e}")
                self.openai_client = None
        
        print("=" * 70)
        print("ğŸ¬ æ»‘å‹•çª—å£æ‰‹èªè­˜åˆ¥ç³»çµ±")
        print("=" * 70)
        print(f"çª—å£å¤§å°: {self.WINDOW_SIZE} å¹€ (~{self.WINDOW_SIZE/self.TARGET_FPS:.2f} ç§’)")
        print(f"æ»‘å‹•æ­¥é•·: {self.stride} å¹€ (~{self.stride/self.TARGET_FPS:.2f} ç§’)")
        print(f"æ”¯æ´ä»»æ„é•·åº¦å½±ç‰‡ï¼ˆæœ€çŸ­éœ€ {self.WINDOW_SIZE} å¹€ï¼‰")
        print("=" * 70)
        
        # è¼‰å…¥æ¨¡å‹
        self._load_model(model_path, label_map_path)
        
        # åˆå§‹åŒ–ç‰¹å¾µæå–å™¨
        self._init_extractors()
        
        # é ç†±æ¨¡å‹
        self._warmup_model()
        
        print("âœ… ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼\n")
    
    def _load_model(self, model_path, label_map_path):
        """è¼‰å…¥æ¨¡å‹å’Œæ¨™ç±¤"""
        print(f"ğŸ“¥ è¼‰å…¥æ¨¡å‹: {model_path}")
        
        # å•Ÿç”¨ unsafe deserializationï¼ˆè™•ç† Lambda å±¤ï¼‰
        keras.config.enable_unsafe_deserialization()
        
        # è¼‰å…¥æ¨¡å‹
        custom_objects = {
            'FocalLoss': FocalLoss,
            'MixupAccuracy': MixupAccuracy,
            'MixupTop3Accuracy': MixupTop3Accuracy
        }
        self.model = keras.models.load_model(model_path, custom_objects=custom_objects)
        keras.mixed_precision.set_global_policy('float32')
        
        # è¼‰å…¥æ¨™ç±¤
        with open(label_map_path, 'r', encoding='utf-8') as f:
            self.label_map = json.load(f)
        self.idx_to_word = {v: k for k, v in self.label_map.items()}
        
        print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼ˆ{len(self.label_map)} å€‹å–®è©ï¼‰")
    
    def _warmup_model(self):
        """é ç†±æ¨¡å‹"""
        print("ğŸ”¥ é ç†±æ¨¡å‹ï¼ˆCPU æ¨¡å¼ï¼‰...")
        dummy_input = np.zeros((1, 300, 1119), dtype=np.float32)
        
        with tf.device('/CPU:0'):
            _ = self.model.predict(dummy_input, verbose=0)
        
        print("âœ… æ¨¡å‹é ç†±å®Œæˆ")
    
    def _init_extractors(self):
        """åˆå§‹åŒ–ç‰¹å¾µæå–å™¨"""
        print("ğŸ”§ åˆå§‹åŒ–ç‰¹å¾µæå–å™¨...")
        
        # RGB ç‰¹å¾µæå–å™¨
        if self.device == 'mps':
            torch_device = torch.device('mps')
            device_type = 'gpu'
        elif self.device == 'gpu':
            torch_device = torch.device('cuda')
            device_type = 'gpu'
        else:
            torch_device = torch.device('cpu')
            device_type = 'cpu'
        
        self.rgb_extractor = RGBFeatureExtractor(torch_device, device_type)
        
        # éª¨æ¶ç‰¹å¾µæå–å™¨
        self.skeleton_extractor = EnhancedSkeletonExtractor(num_threads=4)
        
        print("âœ… ç‰¹å¾µæå–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def load_and_normalize_video(self, video_path):
        """
        è®€å–ä¸¦æ¨™æº–åŒ–å½±ç‰‡
        
        Args:
            video_path: å½±ç‰‡è·¯å¾‘
        
        Returns:
            frames: æ¨™æº–åŒ–å¾Œçš„å¹€åˆ—è¡¨ (T, 224, 224, 3) RGB
        """
        print(f"\nğŸ“¹ è®€å–å½±ç‰‡: {Path(video_path).name}")
        
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            raise RuntimeError(f"ç„¡æ³•é–‹å•Ÿå½±ç‰‡: {video_path}")
        
        # ç²å–å½±ç‰‡è³‡è¨Š
        original_fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / original_fps if original_fps > 0 else 0
        
        print(f"  åŸå§‹è¦æ ¼: {total_frames} å¹€, {original_fps:.2f} fps, {duration:.2f} ç§’")
        
        # è®€å–æ‰€æœ‰å¹€
        all_frames = []
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            all_frames.append(frame)
        
        cap.release()
        
        # é‡æ¡æ¨£åˆ°ç›®æ¨™ FPS
        target_frame_count = int(duration * self.TARGET_FPS)
        if target_frame_count == 0:
            raise ValueError("å½±ç‰‡å¤ªçŸ­")
        
        # ä½¿ç”¨ç·šæ€§æ’å€¼é‡æ¡æ¨£
        indices = np.linspace(0, len(all_frames) - 1, target_frame_count).astype(int)
        resampled_frames = [all_frames[i] for i in indices]
        
        # Resize ä¸¦è½‰æ›ç‚º RGB
        normalized_frames = []
        for frame in resampled_frames:
            frame_resized = cv2.resize(frame, (self.TARGET_WIDTH, self.TARGET_HEIGHT))
            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
            normalized_frames.append(frame_rgb)
        
        print(f"  âœ… æ¨™æº–åŒ–å®Œæˆ: {len(normalized_frames)} å¹€ @ {self.TARGET_FPS} fps")
        
        return normalized_frames
    
    def extract_window_features(self, frames):
        """
        æå–çª—å£ç‰¹å¾µï¼ˆä¸¦è¡Œ RGB + Skeletonï¼‰
        
        Args:
            frames: çª—å£å¹€åˆ—è¡¨ (80, 224, 224, 3)
        
        Returns:
            features: (300, 1119) ç‰¹å¾µçŸ©é™£
        """
        # ä¸¦è¡Œæå–ç‰¹å¾µ
        rgb_features = None
        skeleton_features = None
        errors = []
        
        def extract_rgb():
            nonlocal rgb_features, errors
            try:
                rgb_features = self.rgb_extractor.extract_features_from_frames(frames)
            except Exception as e:
                errors.append(f"RGB: {e}")
        
        def extract_skeleton():
            nonlocal skeleton_features, errors
            try:
                skeleton_features = self.skeleton_extractor.extract_features_from_frames(
                    frames, 
                    frame_width=self.TARGET_WIDTH,
                    frame_height=self.TARGET_HEIGHT
                )
            except Exception as e:
                errors.append(f"Skeleton: {e}")
        
        import threading
        rgb_thread = threading.Thread(target=extract_rgb)
        skeleton_thread = threading.Thread(target=extract_skeleton)
        
        rgb_thread.start()
        skeleton_thread.start()
        
        rgb_thread.join()
        skeleton_thread.join()
        
        if errors:
            raise RuntimeError("; ".join(errors))
        
        if rgb_features is None or skeleton_features is None:
            raise ValueError("ç‰¹å¾µæå–å¤±æ•—")
        
        # èåˆç‰¹å¾µ
        min_len = min(len(rgb_features), len(skeleton_features))
        rgb_features = rgb_features[:min_len]
        skeleton_features = skeleton_features[:min_len]
        
        concat_features = np.concatenate([rgb_features, skeleton_features], axis=1)
        
        # Padding åˆ° 300
        max_length = 300
        if len(concat_features) < max_length:
            padding = np.zeros((max_length - len(concat_features), 1119), dtype=np.float32)
            concat_features = np.concatenate([concat_features, padding], axis=0)
        else:
            concat_features = concat_features[:max_length]
        
        return concat_features
    
    def predict_window(self, features):
        """
        å°å–®å€‹çª—å£é€²è¡Œæ¨è«–
        
        Args:
            features: (300, 1119) ç‰¹å¾µçŸ©é™£
        
        Returns:
            top5: [(å–®è©, ä¿¡å¿ƒåº¦), ...] Top-5 çµæœ
        """
        features_batch = np.expand_dims(features, axis=0)
        
        # å¼·åˆ¶ä½¿ç”¨ CPU æ¨è«–ï¼ˆBiGRU åœ¨ CPU ä¸Šæ¯” MPS å¿« 23 å€ï¼‰
        with tf.device('/CPU:0'):
            predictions = self.model.predict(features_batch, verbose=0)
        
        # ç²å– Top-5
        top_indices = np.argsort(predictions[0])[::-1][:5]
        results = [(self.idx_to_word[idx], float(predictions[0][idx])) for idx in top_indices]
        
        return results
    
    def process_video(self, video_path, save_results=True):
        """
        è™•ç†æ•´å€‹å½±ç‰‡ï¼ˆæ»‘å‹•çª—å£ï¼‰
        
        Args:
            video_path: å½±ç‰‡è·¯å¾‘
            save_results: æ˜¯å¦ä¿å­˜çµæœåˆ° JSON
        
        Returns:
            results: æ‰€æœ‰çª—å£çš„è¾¨è­˜çµæœ
        """
        start_time = time.time()
        
        # 1. è®€å–ä¸¦æ¨™æº–åŒ–å½±ç‰‡
        frames = self.load_and_normalize_video(video_path)
        total_frames = len(frames)
        
        # 2. è¨ˆç®—çª—å£æ•¸é‡
        num_windows = (total_frames - self.WINDOW_SIZE) // self.stride + 1
        if num_windows <= 0:
            raise ValueError(f"å½±ç‰‡å¤ªçŸ­ï¼Œç„¡æ³•å‰µå»ºçª—å£ï¼ˆéœ€è¦è‡³å°‘ {self.WINDOW_SIZE} å¹€ï¼‰")
        
        print(f"\nğŸ”„ é–‹å§‹æ»‘å‹•çª—å£æ¨è«–...")
        print(f"  ç¸½å¹€æ•¸: {total_frames}")
        print(f"  çª—å£æ•¸é‡: {num_windows}")
        print(f"  æ¯å€‹çª—å£: {self.WINDOW_SIZE} å¹€ ({self.WINDOW_SIZE / self.TARGET_FPS:.2f} ç§’)")
        print("=" * 70)
        
        # ç™¼é€åˆå§‹é€²åº¦
        if self.progress_callback:
            self.progress_callback(0, num_windows, "é–‹å§‹è™•ç†å½±ç‰‡")
        
        # 3. éæ­·æ‰€æœ‰çª—å£
        all_results = []
        
        for i in range(num_windows):
            window_start = i * self.stride
            window_end = window_start + self.WINDOW_SIZE
            
            # è¨ˆç®—æ™‚é–“ç¯„åœ
            time_start = window_start / self.TARGET_FPS
            time_end = window_end / self.TARGET_FPS
            
            print(f"\nçª—å£ {i+1}/{num_windows} - æ™‚é–“: {time_start:.2f}s - {time_end:.2f}s")
            
            # ç™¼é€çª—å£é–‹å§‹é€²åº¦
            if self.progress_callback:
                self.progress_callback(i, num_windows, f"è™•ç†çª—å£ {i+1}/{num_windows}")
            
            # æå–çª—å£å¹€
            window_frames = frames[window_start:window_end]
            
            # æå–ç‰¹å¾µ
            t0 = time.time()
            try:
                features = self.extract_window_features(window_frames)
                t1 = time.time()
                print(f"  âœ… ç‰¹å¾µæå–: {(t1-t0)*1000:.0f}ms")
                
                # ç™¼é€ç‰¹å¾µæå–å®Œæˆé€²åº¦
                if self.progress_callback:
                    self.progress_callback(i + 0.3, num_windows, f"ç‰¹å¾µæå–å®Œæˆ - çª—å£ {i+1}")
                
                # æ¨è«–
                t0 = time.time()
                top5 = self.predict_window(features)
                t1 = time.time()
                print(f"  âœ… æ¨è«–: {(t1-t0)*1000:.0f}ms")
                
                # ç™¼é€æ¨è«–å®Œæˆé€²åº¦
                if self.progress_callback:
                    self.progress_callback(i + 0.7, num_windows, f"æ¨è«–å®Œæˆ - çª—å£ {i+1}")
                
                # é¡¯ç¤ºçµæœ
                print(f"  ğŸ¯ Top-5 çµæœ:")
                for j, (word, conf) in enumerate(top5, 1):
                    bar = "â–ˆ" * int(conf * 30)
                    print(f"     {j}. {word:12s} {conf*100:5.2f}% {bar}")
                
                # ä¿å­˜çµæœ
                window_result = {
                    'window_id': i,
                    'frame_start': window_start,
                    'frame_end': window_end,
                    'time_start': round(time_start, 2),
                    'time_end': round(time_end, 2),
                    'top5': [{'word': w, 'confidence': round(c, 4)} for w, c in top5]
                }
                all_results.append(window_result)
                
                # ç™¼é€çª—å£å®Œæˆé€²åº¦
                if self.progress_callback:
                    self.progress_callback(i + 1, num_windows, f"çª—å£ {i+1} å®Œæˆ")
                
            except Exception as e:
                print(f"  âŒ è™•ç†å¤±æ•—: {e}")
                if self.progress_callback:
                    self.progress_callback(i + 1, num_windows, f"çª—å£ {i+1} å¤±æ•—")
                continue
        
        total_time = time.time() - start_time
        
        # 4. è¼¸å‡ºç¸½çµ
        print("\n" + "=" * 70)
        print("ğŸ‰ è™•ç†å®Œæˆï¼")
        print("=" * 70)
        print(f"ç¸½è€—æ™‚: {total_time:.2f}s")
        print(f"è™•ç†çª—å£æ•¸: {len(all_results)}/{num_windows}")
        print(f"å¹³å‡æ¯çª—å£: {total_time/len(all_results):.2f}s")
        
        # 5. ä¿å­˜çµæœ
        if save_results:
            output_file = Path(video_path).stem + "_results.json"
            output_path = Path("outputs") / output_file
            output_path.parent.mkdir(exist_ok=True)
            
            result_data = {
                'video_path': str(video_path),
                'video_name': Path(video_path).name,
                'total_frames': total_frames,
                'duration': round(total_frames / self.TARGET_FPS, 2),
                'num_windows': len(all_results),
                'window_size': self.WINDOW_SIZE,
                'stride': self.stride,
                'processing_time': round(total_time, 2),
                'results': all_results
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ çµæœå·²ä¿å­˜: {output_path}")
        
        return all_results
    
    def compose_sentence_with_openai(self, results):
        """
        ä½¿ç”¨ OpenAI å¾å¤šå€‹çª—å£çš„ Top-5 çµæœä¸­çµ„åˆå‡ºæœ€æœ‰å¯èƒ½çš„å¥å­
        
        Args:
            results: æ‰€æœ‰çª—å£çš„è¾¨è­˜çµæœ
        
        Returns:
            composed_sentence: é‡çµ„å¾Œçš„å¥å­
            explanation: AI çš„è§£é‡‹
        """
        if not self.openai_client:
            # å¦‚æœæ²’æœ‰ OpenAIï¼Œè¿”å› Top-1 å–®è©åºåˆ—
            words = [result['top1'][0] for result in results]
            sentence = ' '.join(words)
            return sentence, "ä½¿ç”¨ Top-1 çµæœçµ„åˆï¼ˆæœªé…ç½® OpenAIï¼‰"
            return None, None
        
        print("\n" + "=" * 70)
        print("ğŸ¤– ä½¿ç”¨ OpenAI åˆ†æä¸¦é‡çµ„å¥å­...")
        print("=" * 70)
        
        # æº–å‚™æç¤ºè©
        prompt = self._build_openai_prompt(results)
        print(f"ğŸ” èª¿è©¦: æç¤ºè©é•·åº¦: {len(prompt)} å­—ç¬¦")
        print(f"ğŸ” èª¿è©¦: çª—å£æ•¸é‡: {len(results)}")
        
        try:
            # ä½¿ç”¨ OpenAI Chat Completions APIï¼ˆGPT-4o-miniï¼‰
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",  # ä½¿ç”¨ç©©å®šå¯é çš„ GPT-4o-mini
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€å€‹æ‰‹èªè­˜åˆ¥çµæœåˆ†æå°ˆå®¶ã€‚ä½ çš„ä»»å‹™æ˜¯å¾å¤šå€‹æ™‚é–“çª—å£çš„æ‰‹èªè­˜åˆ¥çµæœä¸­ï¼Œæ‰¾å‡ºæœ€æœ‰å¯èƒ½çš„å–®è©åºåˆ—ä¸¦çµ„åˆæˆæœ‰æ„ç¾©çš„å¥å­ï¼Œä¸¦ä»¥ä½¿ç”¨è€…çš„è§’åº¦ç™¼æƒ³ã€Œæˆ‘ã€ã€‚

æ³¨æ„äº‹é …ï¼š
1. æ¯å€‹çª—å£éƒ½æœ‰ Top-5 çš„è­˜åˆ¥çµæœåŠå…¶ä¿¡å¿ƒåº¦
2. Top-1 ä¸ä¸€å®šæ˜¯æ­£ç¢ºçš„ï¼Œæ­£ç¢ºçš„å–®è©ä¿¡å¿ƒåº¦é€šå¸¸åœ¨ 10% ä»¥ä¸Š
3. éœ€è¦è€ƒæ…®æ‰‹èªçš„èªæ³•çµæ§‹ï¼ˆå¯èƒ½èˆ‡å£èªä¸åŒï¼‰
4. åŒä¸€å€‹æ‰‹å‹¢å¯èƒ½åœ¨å¤šå€‹çª—å£ä¸­è¢«è­˜åˆ¥ï¼ˆé‡è¤‡ï¼‰
5. éœ€è¦å»é™¤é‡è¤‡çš„å–®è©ï¼Œçµ„åˆæˆæµæš¢çš„å¥å­
6. å¦‚æœæŸå€‹å–®è©åœ¨å¤šå€‹çª—å£ä¸­å‡ºç¾ä¸”ä¿¡å¿ƒåº¦éƒ½è¼ƒé«˜ï¼Œèªªæ˜é€™å€‹å–®è©å¾ˆé‡è¦

è«‹åˆ†ææ‰€æœ‰çª—å£çš„çµæœï¼Œæ‰¾å‡ºæœ€åˆç†çš„å–®è©åºåˆ—ï¼Œä¸¦çµ„åˆæˆå¥å­ã€‚"""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,  # é©ä¸­çš„æº«åº¦ä»¥ç²å¾—ç©©å®šçµæœ
                max_tokens=1000  # GPT-4o-mini ä½¿ç”¨ max_tokens
            )
            
            # è§£æ Chat Completions API çš„å›æ‡‰
            ai_response = response.choices[0].message.content
            
            # å˜—è©¦å¾å›æ‡‰ä¸­æå–å¥å­å’Œè§£é‡‹
            composed_sentence, explanation = self._parse_openai_response(ai_response)
            
            print(f"\nâœ… AI åˆ†æå®Œæˆ")
            print(f"ğŸ¯ é‡çµ„å¥å­: {composed_sentence}")
            print(f"ğŸ’¡ AI è§£é‡‹:\n{explanation}")
            
            return composed_sentence, explanation
            
        except Exception as e:
            print(f"âŒ OpenAI API èª¿ç”¨å¤±æ•—: {e}")
            return None, None
    
    def _build_openai_prompt(self, results):
        """æ§‹å»ºçµ¦ OpenAI çš„æç¤ºè©"""
        prompt = "ä»¥ä¸‹æ˜¯æ‰‹èªè­˜åˆ¥ç³»çµ±å°ä¸€æ®µå½±ç‰‡çš„åˆ†æçµæœï¼Œå…±æœ‰ {} å€‹æ™‚é–“çª—å£ï¼š\n\n".format(len(results))
        
        for result in results:
            window_id = result['window_id'] + 1
            time_range = f"{result['time_start']:.2f}s - {result['time_end']:.2f}s"
            
            prompt += f"çª—å£ {window_id} ({time_range}):\n"
            for i, item in enumerate(result['top5'], 1):
                word = item['word']
                conf = item['confidence'] * 100
                prompt += f"  {i}. {word:12s} {conf:5.2f}%\n"
            prompt += "\n"
        
        prompt += """è«‹åˆ†æä»¥ä¸Šçµæœï¼Œå®Œæˆä»¥ä¸‹ä»»å‹™ï¼š

1. å¾æ¯å€‹çª—å£çš„ Top-5 çµæœä¸­é¸å‡ºæœ€åˆç†çš„å–®è©ï¼ˆä¸ä¸€å®šæ˜¯ Top-1ï¼‰
2. è€ƒæ…®å–®è©çš„ä¿¡å¿ƒåº¦ï¼ˆé€šå¸¸æ­£ç¢ºçš„å–®è©ä¿¡å¿ƒåº¦åœ¨ 10% ä»¥ä¸Šï¼‰
3. å»é™¤é‡è¤‡çš„å–®è©ï¼ˆåŒä¸€å€‹æ‰‹å‹¢å¯èƒ½è·¨è¶Šå¤šå€‹çª—å£ï¼‰
4. ä»¥ä½¿ç”¨è€…ã€Œæˆ‘ã€çš„è§’åº¦ç™¼æƒ³ï¼Œçµ„åˆæˆä¸€å€‹æµæš¢ã€æœ‰æ„ç¾©çš„å¥å­
5. è§£é‡‹ä½ çš„é¸æ“‡ç†ç”±

è«‹ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
å¥å­ï¼š[é‡çµ„å¾Œçš„å¥å­]
è§£é‡‹ï¼š[è©³ç´°èªªæ˜ä½ ç‚ºä»€éº¼é¸æ“‡é€™äº›å–®è©ï¼Œä»¥åŠå¦‚ä½•çµ„åˆçš„]"""
        
        return prompt
    
    def _parse_openai_response(self, response):
        """è§£æ OpenAI çš„å›æ‡‰"""
        lines = response.strip().split('\n')
        sentence = ""
        explanation = ""
        
        current_section = None
        for line in lines:
            line = line.strip()
            if line.startswith("å¥å­ï¼š") or line.startswith("å¥å­:"):
                sentence = line.split("ï¼š", 1)[-1].split(":", 1)[-1].strip()
                current_section = "sentence"
            elif line.startswith("è§£é‡‹ï¼š") or line.startswith("è§£é‡‹:"):
                explanation = line.split("ï¼š", 1)[-1].split(":", 1)[-1].strip()
                current_section = "explanation"
            elif current_section == "explanation" and line:
                explanation += "\n" + line
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™æº–æ ¼å¼ï¼Œå˜—è©¦ç›´æ¥æå–
        if not sentence:
            # å‡è¨­ç¬¬ä¸€è¡Œæ˜¯å¥å­
            sentence = lines[0] if lines else response
        
        if not explanation:
            explanation = response
        
        return sentence, explanation.strip()
    
    def visualize_results(self, results, video_path=None):
        """
        è¦–è¦ºåŒ–çµæœï¼ˆç°¡å–®çš„æ–‡å­—è¡¨æ ¼ï¼‰
        
        Args:
            results: è™•ç†çµæœ
            video_path: åŸå§‹å½±ç‰‡è·¯å¾‘ï¼ˆå¯é¸ï¼‰
        """
        print("\n" + "=" * 70)
        print("ğŸ“Š è¾¨è­˜çµæœç¸½è¦½")
        print("=" * 70)
        
        # çµ±è¨ˆæœ€å¸¸å‡ºç¾çš„å–®è©ï¼ˆTop-1ï¼‰
        word_counts = {}
        for result in results:
            top1_word = result['top5'][0]['word']
            word_counts[top1_word] = word_counts.get(top1_word, 0) + 1
        
        print("\nTop-1 å–®è©çµ±è¨ˆ:")
        for word, count in sorted(word_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"  {word:12s}: {count} æ¬¡")
        
        print("\næ™‚é–“è»¸çµæœ:")
        print(f"{'çª—å£':<6} {'æ™‚é–“ç¯„åœ':<15} {'Top-1 å–®è©':<12} {'ä¿¡å¿ƒåº¦':<8} Top-2 ~ Top-5")
        print("-" * 70)
        
        for result in results:
            window_id = result['window_id'] + 1
            time_range = f"{result['time_start']:.1f}s-{result['time_end']:.1f}s"
            top1 = result['top5'][0]
            top_others = ", ".join([f"{r['word']}({r['confidence']*100:.0f}%)" 
                                   for r in result['top5'][1:]])
            
            print(f"{window_id:<6} {time_range:<15} {top1['word']:<12} "
                  f"{top1['confidence']*100:>5.1f}%   {top_others}")


def main():
    """ä¸»å‡½æ•¸"""
    # ç¡¬ç·¨ç¢¼åƒæ•¸
    video_path = "1.MOV"  # è¼¸å…¥å½±ç‰‡è·¯å¾‘
    model_path = 'model_output/best_model_mps.keras'  # æ¨¡å‹è·¯å¾‘
    label_path = 'model_output/label_map.json'  # æ¨™ç±¤æ˜ å°„è·¯å¾‘
    device = 'mps'  # ç‰¹å¾µæå–è¨­å‚™
    stride = 80  # æ»‘å‹•æ­¥é•·ï¼ˆå¹€æ•¸ï¼‰
    save_results = False  # æ˜¯å¦ä¿å­˜çµæœåˆ° JSONï¼ˆé è¨­ä¸ä¿å­˜ï¼‰
    
    # OpenAI API Keyï¼ˆè«‹è¨­ç½®æ‚¨çš„ API Keyï¼‰
    openai_api_key = os.environ.get('OPENAI_API_KEY')  # å¾ç’°å¢ƒè®Šæ•¸è®€å–
    
    # æª¢æŸ¥æ–‡ä»¶
    video_path_obj = Path(video_path)
    model_path_obj = Path(model_path)
    label_path_obj = Path(label_path)
    
    if not video_path_obj.exists():
        print(f"âŒ å½±ç‰‡ä¸å­˜åœ¨: {video_path_obj}")
        return
    
    if not model_path_obj.exists():
        print(f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {model_path_obj}")
        return
    
    if not label_path_obj.exists():
        print(f"âŒ æ¨™ç±¤æ˜ å°„ä¸å­˜åœ¨: {label_path_obj}")
        return
    
    # å‰µå»ºè­˜åˆ¥å™¨
    recognizer = SlidingWindowInference(
        model_path=model_path_obj,
        label_map_path=label_path_obj,
        device=device,
        stride=stride,
        openai_api_key=openai_api_key
    )
    
    # è™•ç†å½±ç‰‡
    results = recognizer.process_video(
        video_path=video_path_obj,
        save_results=save_results
    )
    
    # è¦–è¦ºåŒ–çµæœ
    recognizer.visualize_results(results, video_path_obj)
    
    # ä½¿ç”¨ OpenAI é‡çµ„å¥å­
    if openai_api_key:
        composed_sentence, explanation = recognizer.compose_sentence_with_openai(results)
        
        # å¦‚æœæˆåŠŸé‡çµ„ï¼Œä¿å­˜åˆ°çµæœä¸­
        if composed_sentence:
            print("\n" + "=" * 70)
            print("ğŸ“ æœ€çµ‚çµæœ")
            print("=" * 70)
            print(f"é‡çµ„å¥å­: {composed_sentence}")
            print("=" * 70)
    else:
        print("\nâš ï¸  æœªè¨­ç½® OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸ï¼Œè·³éå¥å­é‡çµ„åŠŸèƒ½")
        print("ğŸ’¡ æç¤ºï¼šè«‹è¨­ç½®ç’°å¢ƒè®Šæ•¸ 'export OPENAI_API_KEY=your-api-key' æˆ–åœ¨ä»£ç¢¼ä¸­ç¡¬ç·¨ç¢¼")


if __name__ == "__main__":
    main()

