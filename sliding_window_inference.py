#!/usr/bin/env python3
"""
æ»‘å‹•çª—å£æ‰‹èªè­˜åˆ¥è…³æœ¬

âš ï¸  æ¨¡å‹ç‰ˆæœ¬ï¼šv3.0 - Deep Improvementsï¼ˆæ·±åº¦æ”¹é€²ç‰ˆï¼‰

ğŸ¯ v3.0 é—œéµæ”¹é€²ï¼š
1. å¤šå°ºåº¦æ± åŒ–ï¼šGlobalMaxPool + GlobalAvgPool ä¸¦è¯
2. MaxNorm ç´„æŸï¼šé˜²æ­¢æ¥µç«¯ logitsï¼ˆEmbedding=3.0, Logits=1.5ï¼‰
3. Focal Loss (Î³=2.0)ï¼šé™ä½ç°¡å–®æ¨£æœ¬æ¬Šé‡
4. Temperature Scaling (T=1.5)ï¼šæ ¡æº–ä¿¡å¿ƒåº¦åˆ†ä½ˆ
5. Mixup (Î±=0.2)ï¼šbatch ç´šåˆ¥æ¨£æœ¬æ··åˆï¼ˆè¨“ç·´æ™‚ï¼‰
6. Label Smoothing (Îµ=0.1)ï¼šè»ŸåŒ– one-hot æ¨™ç±¤

ğŸ“Š é æœŸæ”¹å–„ï¼š
- ä¿¡å¿ƒåº¦ï¼š70-85%ï¼ˆåŸ 98%+ éæ–¼è‡ªä¿¡ï¼‰
- æº–ç¢ºç‡ï¼š92-96%ï¼ˆåŸ 100% è¡¨ç¤ºéæ“¬åˆï¼‰
- Top-1 åˆ° Top-5 æ¦‚ç‡æ›´å¹³æ»‘
- ç›¸ä¼¼æ‰‹å‹¢ï¼ˆå¦‚ teacher/studentï¼‰ä¸å†æ¥µç«¯èª¤åˆ¤

ğŸ”§ æ¨è«–ç‰¹æ€§ï¼š
- æ‰€æœ‰æ”¹é€²åœ¨æ¨è«–æ™‚è‡ªå‹•ç”Ÿæ•ˆ
- BatchNorm/LayerNorm è‡ªå‹•åˆ‡æ›æ¨è«–æ¨¡å¼
- Temperature Scaling å±¤é€æ˜è™•ç†
- ç„¡éœ€ä»£ç¢¼ä¿®æ”¹

åŠŸèƒ½ï¼š
1. è®€å–ä»»æ„é•·åº¦å½±ç‰‡ï¼ˆæœ€çŸ­ 80 å¹€ï¼‰
2. æ»‘å‹•çª—å£æƒæï¼š80 å¹€/çª—å£ï¼Œå¯èª¿æ­¥é•·
3. æ¯å€‹çª—å£ç¨ç«‹æ¨è«–ï¼šTop-5 çµæœ
4. æ™‚é–“è»¸å¯è¦–åŒ–ï¼šå®Œæ•´è¼¸å‡ºæ‰€æœ‰çª—å£çµæœ
5. JSON çµæœä¿å­˜ï¼šä¾¿æ–¼å¾ŒçºŒåˆ†æ
"""

import os

# ğŸš« ç¦ç”¨ GPU/Metal/OpenGL - å¿…é ˆåœ¨æ‰€æœ‰ import ä¹‹å‰è¨­å®š
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
os.environ['MEDIAPIPE_GPU_DISABLED'] = '1'
os.environ['MEDIAPIPE_DISABLE_GPU'] = '1'
os.environ['MEDIAPIPE_DISABLE_EGL'] = '1'
os.environ['EGL_PLATFORM'] = 'surfaceless'
os.environ['GLOG_logtostderr'] = '1'
# æŠ‘åˆ¶ MediaPipe GPU è©¦æ¢çš„éŒ¯èª¤è¨Šæ¯ï¼ˆ2=åªé¡¯ç¤º ERROR ä»¥ä¸Šï¼‰
os.environ['GLOG_minloglevel'] = '2'

# è¨­ç½® Keras backend ç‚º TensorFlow
os.environ['KERAS_BACKEND'] = 'tensorflow'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import sys
import cv2
import numpy as np
import torch
from pathlib import Path
from datetime import datetime
import json
import time
from openai import OpenAI

import tensorflow as tf
import keras

# å°å…¥æ¨¡çµ„
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent / "feature_extraction"))

from rgb_feature_extraction import RGBFeatureExtractor
from skeleton_feature_extraction import EnhancedSkeletonExtractor


# ==================== è‡ªå®šç¾©å±¤å®šç¾©ï¼ˆè¼‰å…¥æ¨¡å‹éœ€è¦ï¼‰====================
@keras.saving.register_keras_serializable()
class FocalLoss(keras.losses.Loss):
    """Focal Loss"""
    def __init__(self, num_classes=15, gamma=2.0, alpha=None, label_smoothing=0.1, name='focal_loss', **kwargs):
        super().__init__(name=name, **kwargs)
        self.num_classes = num_classes
        self.gamma = gamma
        self.alpha = alpha
        self.label_smoothing = label_smoothing
    def call(self, y_true, y_pred):
        from keras import ops
        if len(ops.shape(y_true)) == 1:
            y_true_one_hot = ops.one_hot(ops.cast(y_true, 'int32'), self.num_classes)
            if self.label_smoothing > 0:
                y_true_one_hot = y_true_one_hot * (1.0 - self.label_smoothing) + self.label_smoothing / self.num_classes
        else:
            y_true_one_hot = y_true
        epsilon = 1e-7
        y_pred = ops.clip(y_pred, epsilon, 1.0 - epsilon)
        cross_entropy = -y_true_one_hot * ops.log(y_pred)
        p_t = ops.sum(y_true_one_hot * y_pred, axis=-1, keepdims=True)
        focal_weight = ops.power(1.0 - p_t, self.gamma)
        focal_cross_entropy = focal_weight * cross_entropy
        if self.alpha is not None:
            alpha_weight = y_true_one_hot * self.alpha
            focal_cross_entropy = alpha_weight * focal_cross_entropy
        return ops.mean(ops.sum(focal_cross_entropy, axis=-1))
    def get_config(self):
        config = super().get_config()
        config.update({'num_classes': self.num_classes, 'gamma': self.gamma, 'alpha': self.alpha, 'label_smoothing': self.label_smoothing})
        return config

@keras.saving.register_keras_serializable()
class MixupAccuracy(keras.metrics.Metric):
    """Mixup Accuracy"""
    def __init__(self, name='mixup_accuracy', **kwargs):
        super().__init__(name=name, **kwargs)
        self.total = self.add_weight(name='total', initializer='zeros')
        self.count = self.add_weight(name='count', initializer='zeros')
    def update_state(self, y_true, y_pred, sample_weight=None):
        from keras import ops
        if len(ops.shape(y_true)) == 1:
            y_true_labels = ops.cast(y_true, 'int32')
        else:
            y_true_labels = ops.argmax(y_true, axis=-1)
        y_pred_labels = ops.argmax(y_pred, axis=-1)
        matches = ops.cast(ops.equal(y_true_labels, y_pred_labels), 'float32')
        self.total.assign_add(ops.sum(matches))
        self.count.assign_add(ops.cast(ops.size(matches), 'float32'))
    def result(self):
        return self.total / self.count
    def reset_state(self):
        self.total.assign(0.0)
        self.count.assign(0.0)

@keras.saving.register_keras_serializable()
class MixupTop3Accuracy(keras.metrics.Metric):
    """Mixup Top-3 Accuracy"""
    def __init__(self, name='mixup_top3_accuracy', **kwargs):
        super().__init__(name=name, **kwargs)
        self.total = self.add_weight(name='total', initializer='zeros')
        self.count = self.add_weight(name='count', initializer='zeros')
    def update_state(self, y_true, y_pred, sample_weight=None):
        from keras import ops
        if len(ops.shape(y_true)) == 1:
            y_true_labels = ops.cast(y_true, 'int32')
        else:
            y_true_labels = ops.argmax(y_true, axis=-1)
        top3_pred = ops.top_k(y_pred, k=3)[1]
        y_true_expanded = ops.expand_dims(y_true_labels, axis=-1)
        matches = ops.any(ops.equal(top3_pred, y_true_expanded), axis=-1)
        matches = ops.cast(matches, 'float32')
        self.total.assign_add(ops.sum(matches))
        self.count.assign_add(ops.cast(ops.size(matches), 'float32'))
    def result(self):
        return self.total / self.count
    def reset_state(self):
        self.total.assign(0.0)
        self.count.assign(0.0)


class SlidingWindowInference:
    """æ»‘å‹•çª—å£æ‰‹èªè­˜åˆ¥å™¨"""
    
    # åƒæ•¸é…ç½®
    WINDOW_SIZE = 80        # æ¯å€‹çª—å£ 80 å¹€ï¼ˆç´„ 2.67 ç§’ @ 30fpsï¼‰
    TARGET_FPS = 30         # ç›®æ¨™å¹€ç‡
    TARGET_WIDTH = 224      # ç›®æ¨™å¯¬åº¦
    TARGET_HEIGHT = 224     # ç›®æ¨™é«˜åº¦
    
    def __init__(self, model_path, label_map_path, device='mps', stride=80, openai_api_key=None, progress_callback=None):
        """
        åˆå§‹åŒ–æ»‘å‹•çª—å£è­˜åˆ¥å™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾‘
            label_map_path: æ¨™ç±¤æ˜ å°„è·¯å¾‘
            device: è¨­å‚™é¡å‹ï¼ˆç”¨æ–¼ç‰¹å¾µæå–å™¨ï¼Œæ¨è«–å¼·åˆ¶ä½¿ç”¨ CPUï¼‰
            stride: æ»‘å‹•æ­¥é•·ï¼ˆå¹€æ•¸ï¼‰
                   - 80 å¹€ï¼ˆé è¨­ï¼‰ï¼šç„¡é‡ç–Šï¼Œæœ€å¿«ï¼Œé©åˆå¿«é€Ÿæƒæ
                   - 60 å¹€ï¼š25% é‡ç–Šï¼Œå¹³è¡¡
                   - 40 å¹€ï¼š50% é‡ç–Šï¼Œæ›´å¯†é›†æª¢æ¸¬
            openai_api_key: OpenAI API é‡‘é‘°ï¼ˆç”¨æ–¼å¥å­é‡çµ„ï¼‰
            progress_callback: é€²åº¦å›èª¿å‡½æ•¸ï¼Œåƒæ•¸ç‚º (current, total, message)
        
        æ³¨æ„ï¼šè¨“ç·´æ•¸æ“šå¹³å‡å–®è©é•·åº¦ç‚º 88 å¹€ï¼ˆ3.1 ç§’ï¼‰
        """
        self.device = device
        self.stride = stride
        self.openai_client = None
        self.progress_callback = progress_callback
        
        # åˆå§‹åŒ– OpenAI
        if openai_api_key:
            try:
                self.openai_client = OpenAI(api_key=openai_api_key)
                print("âœ… OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—: {e}")
                self.openai_client = None
        
        print("=" * 70)
        print("ğŸ¬ æ»‘å‹•çª—å£æ‰‹èªè­˜åˆ¥ç³»çµ±")
        print("=" * 70)
        print(f"çª—å£å¤§å°: {self.WINDOW_SIZE} å¹€ (~{self.WINDOW_SIZE/self.TARGET_FPS:.2f} ç§’)")
        print(f"æ»‘å‹•æ­¥é•·: {self.stride} å¹€ (~{self.stride/self.TARGET_FPS:.2f} ç§’)")
        print(f"æ”¯æ´ä»»æ„é•·åº¦å½±ç‰‡ï¼ˆæœ€çŸ­éœ€ {self.WINDOW_SIZE} å¹€ï¼‰")
        print("=" * 70)
        
        # è¼‰å…¥æ¨¡å‹
        self._load_model(model_path, label_map_path)
        
        # å»¶é²åˆå§‹åŒ–ç‰¹å¾µæå–å™¨ï¼ˆé¦–æ¬¡ä½¿ç”¨æ™‚æ‰è¼‰å…¥ï¼‰
        self.rgb_extractor = None
        self.skeleton_extractor = None
        
        # å»¶é²é ç†±æ¨¡å‹ï¼ˆé¦–æ¬¡æ¨è«–æ™‚è‡ªå‹•é ç†±ï¼‰
        self._model_warmed_up = False
        
        print("âœ… ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼ï¼ˆç‰¹å¾µæå–å™¨å°‡å»¶é²è¼‰å…¥ï¼‰\n")
    
    def _load_model(self, model_path, label_map_path):
        """è¼‰å…¥æ¨¡å‹å’Œæ¨™ç±¤"""
        print(f"ğŸ“¥ è¼‰å…¥æ¨¡å‹: {model_path}")
        
        # å•Ÿç”¨ unsafe deserializationï¼ˆè™•ç† Lambda å±¤ï¼‰
        keras.config.enable_unsafe_deserialization()
        
        # è¼‰å…¥æ¨¡å‹
        custom_objects = {
            'FocalLoss': FocalLoss,
            'MixupAccuracy': MixupAccuracy,
            'MixupTop3Accuracy': MixupTop3Accuracy
        }
        self.model = keras.models.load_model(model_path, custom_objects=custom_objects)
        keras.mixed_precision.set_global_policy('float32')
        
        # è¼‰å…¥æ¨™ç±¤
        with open(label_map_path, 'r', encoding='utf-8') as f:
            self.label_map = json.load(f)
        self.idx_to_word = {v: k for k, v in self.label_map.items()}
        
        print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼ˆ{len(self.label_map)} å€‹å–®è©ï¼‰")
    
    def _ensure_extractors_initialized(self):
        """ç¢ºä¿ç‰¹å¾µæå–å™¨å·²åˆå§‹åŒ–ï¼ˆå»¶é²è¼‰å…¥ï¼‰"""
        if self.rgb_extractor is None or self.skeleton_extractor is None:
            print("ğŸ”§ åˆå§‹åŒ–ç‰¹å¾µæå–å™¨...")
            
            # RGB ç‰¹å¾µæå–å™¨
            if self.device == 'mps':
                torch_device = torch.device('mps')
                device_type = 'gpu'
            elif self.device == 'gpu':
                torch_device = torch.device('cuda')
                device_type = 'gpu'
            else:
                torch_device = torch.device('cpu')
                device_type = 'cpu'
            
            self.rgb_extractor = RGBFeatureExtractor(torch_device, device_type)
            
            # éª¨æ¶ç‰¹å¾µæå–å™¨
            self.skeleton_extractor = EnhancedSkeletonExtractor(num_threads=4)
            
            print("âœ… ç‰¹å¾µæå–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _ensure_model_warmed_up(self):
        """ç¢ºä¿æ¨¡å‹å·²é ç†±ï¼ˆå»¶é²é ç†±ï¼‰"""
        if not self._model_warmed_up:
            print("ğŸ”¥ é ç†±æ¨¡å‹ï¼ˆCPU æ¨¡å¼ï¼‰...")
            dummy_input = np.zeros((1, 300, 1119), dtype=np.float32)
            
            with tf.device('/CPU:0'):
                _ = self.model.predict(dummy_input, verbose=0)
            
            self._model_warmed_up = True
            print("âœ… æ¨¡å‹é ç†±å®Œæˆ")
    
    def load_and_normalize_video(self, video_path):
        """
        è®€å–ä¸¦æ¨™æº–åŒ–å½±ç‰‡

        é‡å°ä¸è¶³æ™‚é–“çª—å£çš„å½±ç‰‡è™•ç†ç­–ç•¥ï¼š
        1. å¦‚æœå¹€æ•¸æ¥è¿‘80å¹€ï¼ˆå·®è· â‰¤ 20å¹€ï¼‰ï¼šç·šæ€§æ’å€¼è£œé½Šåˆ°80å¹€
        2. å¦‚æœå·®è·éå¤§ï¼šåŠ é€Ÿå½±ç‰‡åˆ°å‰›å¥½80å¹€

        Args:
            video_path: å½±ç‰‡è·¯å¾‘

        Returns:
            frames: æ¨™æº–åŒ–å¾Œçš„å¹€åˆ—è¡¨ (T, 224, 224, 3) RGB
        """
        print(f"\nğŸ“¹ è®€å–å½±ç‰‡: {Path(video_path).name}")

        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            raise RuntimeError(f"ç„¡æ³•é–‹å•Ÿå½±ç‰‡: {video_path}")

        # ç²å–å½±ç‰‡è³‡è¨Š
        original_fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / original_fps if original_fps > 0 else 0

        print(f"  åŸå§‹è¦æ ¼: {total_frames} å¹€, {original_fps:.2f} fps, {duration:.2f} ç§’")

        # è®€å–æ‰€æœ‰å¹€
        all_frames = []
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            all_frames.append(frame)

        cap.release()

        # ç¢ºå®šç›®æ¨™å¹€æ•¸ç­–ç•¥
        WINDOW_SIZE = 80  # æ™‚é–“çª—å£å¤§å°
        MAX_INTERPOLATION_GAP = 20  # æœ€å¤§ç·šæ€§æ’å€¼å·®è·

        if len(all_frames) < WINDOW_SIZE:
            # å½±ç‰‡å¤ªçŸ­ï¼Œéœ€è¦è£œå¹€
            gap = WINDOW_SIZE - len(all_frames)

            if gap <= MAX_INTERPOLATION_GAP:
                # å·®è·ä¸å¤§ï¼šç·šæ€§æ’å€¼è£œé½Šåˆ°80å¹€
                print(f"  ğŸ”§ å½±ç‰‡å¹€æ•¸ä¸è¶³ ({len(all_frames)} < {WINDOW_SIZE})ï¼Œä½¿ç”¨ç·šæ€§æ’å€¼è£œé½Š")
                target_frame_count = WINDOW_SIZE
                processing_method = "ç·šæ€§æ’å€¼è£œé½Š"
            else:
                # å·®è·éå¤§ï¼šå‡å‹»é‡è¤‡å¹€å¡«å……åˆ°80å¹€
                print(f"  ğŸ”„ å½±ç‰‡å¹€æ•¸åš´é‡ä¸è¶³ ({len(all_frames)} < {WINDOW_SIZE})ï¼Œå‡å‹»é‡è¤‡å¹€å¡«å……åˆ°{WINDOW_SIZE}å¹€")
                target_frame_count = WINDOW_SIZE
                processing_method = "å‡å‹»é‡è¤‡å¡«å……"
        else:
            # å½±ç‰‡è¶³å¤ é•·ï¼Œä¿æŒåŸå§‹å¹€æ•¸ï¼ˆé™¤ééœ€è¦èª¿æ•´åˆ°ç›®æ¨™FPSï¼‰
            original_frame_count = len(all_frames)

            # æª¢æŸ¥æ˜¯å¦éœ€è¦èª¿æ•´åˆ°ç›®æ¨™FPS
            expected_frame_count = int(duration * self.TARGET_FPS)
            if abs(original_frame_count - expected_frame_count) / max(original_frame_count, expected_frame_count) < 0.1:
                # FPSç›¸è¿‘ï¼Œä¿æŒåŸå§‹å¹€æ•¸
                target_frame_count = original_frame_count
                processing_method = "ä¿æŒåŸå§‹é•·åº¦"
            else:
                # FPSå·®ç•°å¤§ï¼Œä½¿ç”¨æ¨™æº–é‡æ¡æ¨£
                target_frame_count = max(expected_frame_count, WINDOW_SIZE)
                processing_method = "æ¨™æº–é‡æ¡æ¨£"

        # ç¢ºä¿è‡³å°‘æœ‰WINDOW_SIZEå¹€
        if target_frame_count < WINDOW_SIZE:
            target_frame_count = WINDOW_SIZE

        print(f"  ğŸ¯ è™•ç†ç­–ç•¥: {processing_method}")
        print(f"  ğŸ“Š ç›®æ¨™å¹€æ•¸: {target_frame_count} (çª—å£å¤§å°: {WINDOW_SIZE})")

        # æ ¹æ“šè™•ç†ç­–ç•¥é¸æ“‡é‡æ¡æ¨£æ–¹æ³•
        if processing_method == "å‡å‹»é‡è¤‡å¡«å……":
            # å‡å‹»é‡è¤‡ç¾æœ‰å¹€ä¾†å¡«å……
            # è¨ˆç®—æ¯å¹€éœ€è¦é‡è¤‡çš„æ¬¡æ•¸
            repeat_factor = target_frame_count / len(all_frames)
            repeated_frames = []

            for i, frame in enumerate(all_frames):
                # è¨ˆç®—é€™å¹€æ‡‰è©²é‡è¤‡å¤šå°‘æ¬¡
                repeat_count = int(np.ceil((i + 1) * repeat_factor)) - int(np.ceil(i * repeat_factor))
                repeated_frames.extend([frame] * repeat_count)

            # ç¢ºä¿ç¸½æ•¸æ­£ç¢º
            if len(repeated_frames) > target_frame_count:
                repeated_frames = repeated_frames[:target_frame_count]
            elif len(repeated_frames) < target_frame_count:
                # å¦‚æœé‚„ä¸å¤ ï¼Œç”¨æœ€å¾Œä¸€å¹€å¡«å……
                last_frame = all_frames[-1]
                repeated_frames.extend([last_frame] * (target_frame_count - len(repeated_frames)))

            resampled_frames = repeated_frames
            print(f"  ğŸ”„ å‡å‹»é‡è¤‡: æ¯å¹€å¹³å‡é‡è¤‡ {repeat_factor:.1f} æ¬¡")
        else:
            # ç·šæ€§æ’å€¼é‡æ¡æ¨£ï¼ˆé©ç”¨æ–¼å…¶ä»–æƒ…æ³ï¼‰
            indices = np.linspace(0, len(all_frames) - 1, target_frame_count).astype(int)
            resampled_frames = [all_frames[i] for i in indices]

        # Resize ä¸¦è½‰æ›ç‚º RGB
        normalized_frames = []
        for frame in resampled_frames:
            frame_resized = cv2.resize(frame, (self.TARGET_WIDTH, self.TARGET_HEIGHT))
            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
            normalized_frames.append(frame_rgb)

        # è¨ˆç®—æœ€çµ‚çš„ç­‰æ•ˆFPS
        final_duration = len(normalized_frames) / self.TARGET_FPS if hasattr(self, 'TARGET_FPS') else duration
        effective_fps = len(normalized_frames) / final_duration if final_duration > 0 else original_fps

        print(f"  âœ… è™•ç†å®Œæˆ: {len(normalized_frames)} å¹€ @ {effective_fps:.2f} fps")
        print(f"  ğŸ“ˆ å¹€æ•¸è®ŠåŒ–: {total_frames} â†’ {len(normalized_frames)} (+{len(normalized_frames) - total_frames})")

        return normalized_frames
    
    def extract_window_features(self, frames):
        """
        æå–çª—å£ç‰¹å¾µï¼ˆä¸¦è¡Œ RGB + Skeletonï¼‰

        Args:
            frames: çª—å£å¹€åˆ—è¡¨ (80, 224, 224, 3)

        Returns:
            features: (300, 1119) ç‰¹å¾µçŸ©é™£
        """
        # ç¢ºä¿ç‰¹å¾µæå–å™¨å·²åˆå§‹åŒ–
        self._ensure_extractors_initialized()

        # ä¸¦è¡Œæå–ç‰¹å¾µ
        rgb_features = None
        skeleton_features = None
        errors = []
        
        def extract_rgb():
            nonlocal rgb_features, errors
            try:
                rgb_features = self.rgb_extractor.extract_features_from_frames(frames)
            except Exception as e:
                errors.append(f"RGB: {e}")
        
        def extract_skeleton():
            nonlocal skeleton_features, errors
            try:
                skeleton_features = self.skeleton_extractor.extract_features_from_frames(
                    frames, 
                    frame_width=self.TARGET_WIDTH,
                    frame_height=self.TARGET_HEIGHT
                )
            except Exception as e:
                errors.append(f"Skeleton: {e}")
        
        import threading
        rgb_thread = threading.Thread(target=extract_rgb)
        skeleton_thread = threading.Thread(target=extract_skeleton)
        
        rgb_thread.start()
        skeleton_thread.start()
        
        rgb_thread.join()
        skeleton_thread.join()
        
        if errors:
            raise RuntimeError("; ".join(errors))
        
        if rgb_features is None or skeleton_features is None:
            raise ValueError("ç‰¹å¾µæå–å¤±æ•—")
        
        # èåˆç‰¹å¾µ
        min_len = min(len(rgb_features), len(skeleton_features))
        rgb_features = rgb_features[:min_len]
        skeleton_features = skeleton_features[:min_len]
        
        concat_features = np.concatenate([rgb_features, skeleton_features], axis=1)
        
        # Padding åˆ° 300
        max_length = 300
        if len(concat_features) < max_length:
            padding = np.zeros((max_length - len(concat_features), 1119), dtype=np.float32)
            concat_features = np.concatenate([concat_features, padding], axis=0)
        else:
            concat_features = concat_features[:max_length]
        
        return concat_features
    
    def predict_window(self, features):
        """
        å°å–®å€‹çª—å£é€²è¡Œæ¨è«–

        Args:
            features: (300, 1119) ç‰¹å¾µçŸ©é™£

        Returns:
            top5: [(å–®è©, ä¿¡å¿ƒåº¦), ...] Top-5 çµæœ
        """
        # ç¢ºä¿æ¨¡å‹å·²é ç†±
        self._ensure_model_warmed_up()

        features_batch = np.expand_dims(features, axis=0)

        # å¼·åˆ¶ä½¿ç”¨ CPU æ¨è«–ï¼ˆBiGRU åœ¨ CPU ä¸Šæ¯” MPS å¿« 23 å€ï¼‰
        with tf.device('/CPU:0'):
            predictions = self.model.predict(features_batch, verbose=0)

        # ç²å– Top-5
        top_indices = np.argsort(predictions[0])[::-1][:5]
        results = [(self.idx_to_word[idx], float(predictions[0][idx])) for idx in top_indices]

        return results
    
    def process_video(self, video_path, save_results=True):
        """
        è™•ç†æ•´å€‹å½±ç‰‡ï¼ˆæ»‘å‹•çª—å£ï¼‰
        
        Args:
            video_path: å½±ç‰‡è·¯å¾‘
            save_results: æ˜¯å¦ä¿å­˜çµæœåˆ° JSON
        
        Returns:
            results: æ‰€æœ‰çª—å£çš„è¾¨è­˜çµæœ
        """
        start_time = time.time()
        
        # 1. è®€å–ä¸¦æ¨™æº–åŒ–å½±ç‰‡
        frames = self.load_and_normalize_video(video_path)
        total_frames = len(frames)
        
        # 2. è¨ˆç®—çª—å£æ•¸é‡
        num_windows = (total_frames - self.WINDOW_SIZE) // self.stride + 1
        if num_windows <= 0:
            raise ValueError(f"å½±ç‰‡å¤ªçŸ­ï¼Œç„¡æ³•å‰µå»ºçª—å£ï¼ˆéœ€è¦è‡³å°‘ {self.WINDOW_SIZE} å¹€ï¼‰")
        
        print(f"\nğŸ”„ é–‹å§‹æ»‘å‹•çª—å£æ¨è«–...")
        print(f"  ç¸½å¹€æ•¸: {total_frames}")
        print(f"  çª—å£æ•¸é‡: {num_windows}")
        print(f"  æ¯å€‹çª—å£: {self.WINDOW_SIZE} å¹€ ({self.WINDOW_SIZE / self.TARGET_FPS:.2f} ç§’)")
        print("=" * 70)
        
        # ç™¼é€åˆå§‹é€²åº¦
        if self.progress_callback:
            self.progress_callback(0, num_windows, "é–‹å§‹è™•ç†å½±ç‰‡")
        
        # 3. éæ­·æ‰€æœ‰çª—å£
        all_results = []
        
        for i in range(num_windows):
            window_start = i * self.stride
            window_end = window_start + self.WINDOW_SIZE
            
            # è¨ˆç®—æ™‚é–“ç¯„åœ
            time_start = window_start / self.TARGET_FPS
            time_end = window_end / self.TARGET_FPS
            
            print(f"\nçª—å£ {i+1}/{num_windows} - æ™‚é–“: {time_start:.2f}s - {time_end:.2f}s")
            
            # ç™¼é€çª—å£é–‹å§‹é€²åº¦
            if self.progress_callback:
                self.progress_callback(i, num_windows, f"è™•ç†çª—å£ {i+1}/{num_windows}")
            
            # æå–çª—å£å¹€
            window_frames = frames[window_start:window_end]
            
            # æå–ç‰¹å¾µ
            t0 = time.time()
            try:
                features = self.extract_window_features(window_frames)
                t1 = time.time()
                print(f"  âœ… ç‰¹å¾µæå–: {(t1-t0)*1000:.0f}ms")
                
                # ç™¼é€ç‰¹å¾µæå–å®Œæˆé€²åº¦
                if self.progress_callback:
                    self.progress_callback(i + 0.3, num_windows, f"ç‰¹å¾µæå–å®Œæˆ - çª—å£ {i+1}")
                
                # æ¨è«–
                t0 = time.time()
                top5 = self.predict_window(features)
                t1 = time.time()
                print(f"  âœ… æ¨è«–: {(t1-t0)*1000:.0f}ms")
                
                # ç™¼é€æ¨è«–å®Œæˆé€²åº¦
                if self.progress_callback:
                    self.progress_callback(i + 0.7, num_windows, f"æ¨è«–å®Œæˆ - çª—å£ {i+1}")
                
                # é¡¯ç¤ºçµæœ
                print(f"  ğŸ¯ Top-5 çµæœ:")
                for j, (word, conf) in enumerate(top5, 1):
                    bar = "â–ˆ" * int(conf * 30)
                    print(f"     {j}. {word:12s} {conf*100:5.2f}% {bar}")
                
                # ä¿å­˜çµæœ
                window_result = {
                    'window_id': i,
                    'frame_start': window_start,
                    'frame_end': window_end,
                    'time_start': round(time_start, 2),
                    'time_end': round(time_end, 2),
                    'top5': [{'word': w, 'confidence': round(c, 4)} for w, c in top5]
                }
                all_results.append(window_result)
                
                # ç™¼é€çª—å£å®Œæˆé€²åº¦
                if self.progress_callback:
                    self.progress_callback(i + 1, num_windows, f"çª—å£ {i+1} å®Œæˆ")
                
            except Exception as e:
                print(f"  âŒ è™•ç†å¤±æ•—: {e}")
                if self.progress_callback:
                    self.progress_callback(i + 1, num_windows, f"çª—å£ {i+1} å¤±æ•—")
                continue
        
        total_time = time.time() - start_time
        
        # 4. è¼¸å‡ºç¸½çµ
        print("\n" + "=" * 70)
        print("ğŸ‰ è™•ç†å®Œæˆï¼")
        print("=" * 70)
        print(f"ç¸½è€—æ™‚: {total_time:.2f}s")
        print(f"è™•ç†çª—å£æ•¸: {len(all_results)}/{num_windows}")
        if len(all_results) > 0:
            print(f"å¹³å‡æ¯çª—å£: {total_time/len(all_results):.2f}s")
        else:
            print("å¹³å‡æ¯çª—å£: N/A (ç„¡æˆåŠŸè™•ç†çª—å£)")
        
        # 5. ä¿å­˜çµæœ
        if save_results:
            output_file = Path(video_path).stem + "_results.json"
            output_path = Path("outputs") / output_file
            output_path.parent.mkdir(exist_ok=True)
            
            result_data = {
                'video_path': str(video_path),
                'video_name': Path(video_path).name,
                'total_frames': total_frames,
                'duration': round(total_frames / self.TARGET_FPS, 2),
                'num_windows': len(all_results),
                'window_size': self.WINDOW_SIZE,
                'stride': self.stride,
                'processing_time': round(total_time, 2),
                'results': all_results
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ çµæœå·²ä¿å­˜: {output_path}")
        
        return all_results
    
    def compose_sentence_with_openai(self, results, target_language='ç¹é«”ä¸­æ–‡'):
        """
        ä½¿ç”¨ OpenAI å¾å¤šå€‹çª—å£çš„ Top-5 çµæœä¸­çµ„åˆå‡ºæœ€æœ‰å¯èƒ½çš„å¥å­
        
        Args:
            results: æ‰€æœ‰çª—å£çš„è¾¨è­˜çµæœ
            target_language: ç›®æ¨™èªè¨€ï¼ˆç¹é«”ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ“æ–‡ç­‰ï¼‰
        
        Returns:
            composed_sentence: é‡çµ„å¾Œçš„å¥å­
            explanation: AI çš„è§£é‡‹
        """
        if not self.openai_client:
            # å¦‚æœæ²’æœ‰ OpenAIï¼Œè¿”å› Top-1 å–®è©åºåˆ—
            words = [result['top5'][0]['word'] for result in results]
            sentence = ' '.join(words)
            return sentence, "ä½¿ç”¨ Top-1 çµæœçµ„åˆï¼ˆæœªé…ç½® OpenAIï¼‰"
        
        print("\n" + "=" * 70)
        print(f"ğŸ¤– ä½¿ç”¨ OpenAI åˆ†æä¸¦é‡çµ„å¥å­ï¼ˆç›®æ¨™èªè¨€: {target_language}ï¼‰...")
        print("=" * 70)
        
        # æº–å‚™æç¤ºè©
        prompt = self._build_openai_prompt(results, target_language)
        print(f"ğŸ” èª¿è©¦: æç¤ºè©é•·åº¦: {len(prompt)} å­—ç¬¦")
        print(f"ğŸ” èª¿è©¦: çª—å£æ•¸é‡: {len(results)}")
        
        try:
            # ä½¿ç”¨ OpenAI Chat Completions APIï¼ˆGPT-4o-miniï¼‰
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",  # ä½¿ç”¨ç©©å®šå¯é çš„ GPT-4o-mini
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€å€‹æ‰‹èªè­˜åˆ¥çµæœåˆ†æå°ˆå®¶ã€‚ä½ çš„ä»»å‹™æ˜¯å¾å¤šå€‹æ™‚é–“çª—å£çš„æ‰‹èªè­˜åˆ¥çµæœä¸­ï¼Œç‚ºæ¯å€‹çª—å£é¸å‡ºä¸€å€‹æœ€åˆç†çš„å–®è©ï¼Œç„¶å¾Œçµ„åˆæˆæœ‰æ„ç¾©çš„å¥å­ï¼Œä¸¦ä»¥ä½¿ç”¨è€…çš„è§’åº¦ç™¼æƒ³ã€Œæˆ‘ã€ã€‚

é—œéµè¦å‰‡ï¼š
1. **æ¯å€‹çª—å£åªé¸ä¸€å€‹å–®è©**ï¼ˆå¾ Top-5 ä¸­æŒ‘é¸ï¼Œä¸ä¸€å®šæ˜¯ Top-1ï¼‰
2. é¸æ“‡ä¾æ“šï¼šä¿¡å¿ƒåº¦ï¼ˆé€šå¸¸æ­£ç¢ºçš„å–®è© â‰¥ 10%ï¼‰+ èªç¾©åˆç†æ€§
3. å»é™¤é‡è¤‡å–®è©ï¼ˆç›¸é„°çª—å£å¯èƒ½è­˜åˆ¥åŒä¸€å€‹æ‰‹å‹¢ï¼‰
4. çµ„åˆæˆç¬¦åˆæ‰‹èªèªæ³•çš„æµæš¢å¥å­ï¼ˆå¯èƒ½èˆ‡å£èªé †åºä¸åŒï¼‰
5. å¦‚æœæŸå€‹å–®è©åœ¨å¤šå€‹é€£çºŒçª—å£ä¸­é«˜ä¿¡å¿ƒåº¦å‡ºç¾ï¼Œåªä¿ç•™ä¸€æ¬¡

è«‹ç‚ºæ¯å€‹çª—å£é¸å‡ºä¸€å€‹å–®è©ï¼Œç„¶å¾Œçµ„åˆæˆå¥å­ã€‚"""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,  # é©ä¸­çš„æº«åº¦ä»¥ç²å¾—ç©©å®šçµæœ
                max_tokens=1000  # GPT-4o-mini ä½¿ç”¨ max_tokens
            )
            
            # è§£æ Chat Completions API çš„å›æ‡‰
            ai_response = response.choices[0].message.content
            
            # å˜—è©¦å¾å›æ‡‰ä¸­æå–å¥å­å’Œè§£é‡‹
            composed_sentence, explanation = self._parse_openai_response(ai_response)
            
            print(f"\nâœ… AI åˆ†æå®Œæˆ")
            print(f"ğŸ¯ é‡çµ„å¥å­: {composed_sentence}")
            print(f"ğŸ’¡ AI è§£é‡‹:\n{explanation}")
            
            return composed_sentence, explanation
            
        except Exception as e:
            print(f"âŒ OpenAI API èª¿ç”¨å¤±æ•—: {e}")
            return None, None
    
    def _build_openai_prompt(self, results, target_language='ç¹é«”ä¸­æ–‡'):
        """æ§‹å»ºçµ¦ OpenAI çš„æç¤ºè©"""
        prompt = "ä»¥ä¸‹æ˜¯æ‰‹èªè­˜åˆ¥ç³»çµ±å°ä¸€æ®µå½±ç‰‡çš„åˆ†æçµæœï¼Œå…±æœ‰ {} å€‹æ™‚é–“çª—å£ï¼š\n\n".format(len(results))
        
        for result in results:
            window_id = result['window_id'] + 1
            time_range = f"{result['time_start']:.2f}s - {result['time_end']:.2f}s"
            
            prompt += f"çª—å£ {window_id} ({time_range}):\n"
            for i, item in enumerate(result['top5'], 1):
                word = item['word']
                conf = item['confidence'] * 100
                prompt += f"  {i}. {word:12s} {conf:5.2f}%\n"
            prompt += "\n"
        
        prompt += f"""è«‹åˆ†æä»¥ä¸Šçµæœï¼Œå®Œæˆä»¥ä¸‹ä»»å‹™ï¼š

**ä»»å‹™æµç¨‹ï¼š**
1. ç‚ºæ¯å€‹çª—å£å¾ Top-5 ä¸­é¸å‡º**ä¸€å€‹**æœ€åˆç†çš„å–®è©ï¼ˆä¸ä¸€å®šæ˜¯ Top-1ï¼‰
2. è€ƒæ…®ä¿¡å¿ƒåº¦ï¼šé€šå¸¸æ­£ç¢ºçš„å–®è© â‰¥ 10%
3. å»é™¤ç›¸é„°çª—å£çš„é‡è¤‡å–®è©ï¼ˆåŒä¸€å€‹æ‰‹å‹¢å¯èƒ½è·¨è¶Šå¤šå€‹çª—å£ï¼‰
4. ä»¥ä½¿ç”¨è€…ã€Œæˆ‘ã€çš„è§’åº¦ï¼Œçµ„åˆæˆæµæš¢ã€æœ‰æ„ç¾©çš„å¥å­
5. èªªæ˜æ¯å€‹çª—å£çš„é¸æ“‡ç†ç”±
6. **æœ€çµ‚å¥å­å¿…é ˆç¿»è­¯æˆ{target_language}**ï¼ˆä¿æŒæ‰‹èªåŸæ„ï¼‰

**è¼¸å‡ºæ ¼å¼ï¼š**
å¥å­ï¼š[é‡çµ„å¾Œçš„{target_language}å¥å­]
è§£é‡‹ï¼š
- çª—å£1: é¸æ“‡ã€ŒXXXã€ï¼Œå› ç‚º...
- çª—å£2: é¸æ“‡ã€ŒYYYã€ï¼Œå› ç‚º...
- ...
- æœ€çµ‚çµ„åˆé‚è¼¯ï¼š[èªªæ˜å¦‚ä½•è™•ç†é‡è¤‡ã€èª¿æ•´é †åºç­‰]"""
        
        return prompt
    
    def _parse_openai_response(self, response):
        """è§£æ OpenAI çš„å›æ‡‰"""
        lines = response.strip().split('\n')
        sentence = ""
        explanation = ""
        
        current_section = None
        for line in lines:
            line = line.strip()
            if line.startswith("å¥å­ï¼š") or line.startswith("å¥å­:"):
                sentence = line.split("ï¼š", 1)[-1].split(":", 1)[-1].strip()
                current_section = "sentence"
            elif line.startswith("è§£é‡‹ï¼š") or line.startswith("è§£é‡‹:"):
                explanation = line.split("ï¼š", 1)[-1].split(":", 1)[-1].strip()
                current_section = "explanation"
            elif current_section == "explanation" and line:
                explanation += "\n" + line
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™æº–æ ¼å¼ï¼Œå˜—è©¦ç›´æ¥æå–
        if not sentence:
            # å‡è¨­ç¬¬ä¸€è¡Œæ˜¯å¥å­
            sentence = lines[0] if lines else response
        
        if not explanation:
            explanation = response
        
        return sentence, explanation.strip()
    
    def visualize_results(self, results, video_path=None):
        """
        è¦–è¦ºåŒ–çµæœï¼ˆç°¡å–®çš„æ–‡å­—è¡¨æ ¼ï¼‰
        
        Args:
            results: è™•ç†çµæœ
            video_path: åŸå§‹å½±ç‰‡è·¯å¾‘ï¼ˆå¯é¸ï¼‰
        """
        print("\n" + "=" * 70)
        print("ğŸ“Š è¾¨è­˜çµæœç¸½è¦½")
        print("=" * 70)
        
        # çµ±è¨ˆæœ€å¸¸å‡ºç¾çš„å–®è©ï¼ˆTop-1ï¼‰
        word_counts = {}
        for result in results:
            top1_word = result['top5'][0]['word']
            word_counts[top1_word] = word_counts.get(top1_word, 0) + 1
        
        print("\nTop-1 å–®è©çµ±è¨ˆ:")
        for word, count in sorted(word_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"  {word:12s}: {count} æ¬¡")
        
        print("\næ™‚é–“è»¸çµæœ:")
        print(f"{'çª—å£':<6} {'æ™‚é–“ç¯„åœ':<15} {'Top-1 å–®è©':<12} {'ä¿¡å¿ƒåº¦':<8} Top-2 ~ Top-5")
        print("-" * 70)
        
        for result in results:
            window_id = result['window_id'] + 1
            time_range = f"{result['time_start']:.1f}s-{result['time_end']:.1f}s"
            top1 = result['top5'][0]
            top_others = ", ".join([f"{r['word']}({r['confidence']*100:.0f}%)" 
                                   for r in result['top5'][1:]])
            
            print(f"{window_id:<6} {time_range:<15} {top1['word']:<12} "
                  f"{top1['confidence']*100:>5.1f}%   {top_others}")


def main():
    """ä¸»å‡½æ•¸"""
    # ç¡¬ç·¨ç¢¼åƒæ•¸
    video_path = "1.MOV"  # è¼¸å…¥å½±ç‰‡è·¯å¾‘
    model_path = 'model_output/best_model_mps.keras'  # æ¨¡å‹è·¯å¾‘
    label_path = 'model_output/label_map.json'  # æ¨™ç±¤æ˜ å°„è·¯å¾‘
    device = 'mps'  # ç‰¹å¾µæå–è¨­å‚™
    stride = 80  # æ»‘å‹•æ­¥é•·ï¼ˆå¹€æ•¸ï¼‰
    save_results = False  # æ˜¯å¦ä¿å­˜çµæœåˆ° JSONï¼ˆé è¨­ä¸ä¿å­˜ï¼‰
    
    # OpenAI API Keyï¼ˆè«‹è¨­ç½®æ‚¨çš„ API Keyï¼‰
    openai_api_key = os.environ.get('OPENAI_API_KEY')  # å¾ç’°å¢ƒè®Šæ•¸è®€å–
    
    # æª¢æŸ¥æ–‡ä»¶
    video_path_obj = Path(video_path)
    model_path_obj = Path(model_path)
    label_path_obj = Path(label_path)
    
    if not video_path_obj.exists():
        print(f"âŒ å½±ç‰‡ä¸å­˜åœ¨: {video_path_obj}")
        return
    
    if not model_path_obj.exists():
        print(f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {model_path_obj}")
        return
    
    if not label_path_obj.exists():
        print(f"âŒ æ¨™ç±¤æ˜ å°„ä¸å­˜åœ¨: {label_path_obj}")
        return
    
    # å‰µå»ºè­˜åˆ¥å™¨
    recognizer = SlidingWindowInference(
        model_path=model_path_obj,
        label_map_path=label_path_obj,
        device=device,
        stride=stride,
        openai_api_key=openai_api_key
    )
    
    # è™•ç†å½±ç‰‡
    results = recognizer.process_video(
        video_path=video_path_obj,
        save_results=save_results
    )
    
    # è¦–è¦ºåŒ–çµæœ
    recognizer.visualize_results(results, video_path_obj)
    
    # ä½¿ç”¨ OpenAI é‡çµ„å¥å­
    if openai_api_key:
        composed_sentence, explanation = recognizer.compose_sentence_with_openai(results)
        
        # å¦‚æœæˆåŠŸé‡çµ„ï¼Œä¿å­˜åˆ°çµæœä¸­
        if composed_sentence:
            print("\n" + "=" * 70)
            print("ğŸ“ æœ€çµ‚çµæœ")
            print("=" * 70)
            print(f"é‡çµ„å¥å­: {composed_sentence}")
            print("=" * 70)
    else:
        print("\nâš ï¸  æœªè¨­ç½® OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸ï¼Œè·³éå¥å­é‡çµ„åŠŸèƒ½")
        print("ğŸ’¡ æç¤ºï¼šè«‹è¨­ç½®ç’°å¢ƒè®Šæ•¸ 'export OPENAI_API_KEY=your-api-key' æˆ–åœ¨ä»£ç¢¼ä¸­ç¡¬ç·¨ç¢¼")


if __name__ == "__main__":
    main()

