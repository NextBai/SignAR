#!/usr/bin/env python3
"""
RGBæµç‰¹å¾µæå– - MobileNetV3
TPU å„ªå…ˆï¼ŒGPU é™ç´šï¼Œä½¿ç”¨ MobileNetV3 æå–è¦–è¦ºç‰¹å¾µ
"""

import os
import cv2
import torch
import torch.nn as nn
import numpy as np
from pathlib import Path
from tqdm import tqdm
import zipfile
from datetime import datetime
import json

try:
    import torchvision.models as models
    import torchvision.transforms as transforms
except ImportError as e:
    raise ImportError("âŒ è«‹å®‰è£ torchvision: pip install torchvision") from e


def get_device():
    """è‡ªå‹•æª¢æ¸¬è¨­å‚™ï¼šTPU > GPU > MPS > CPU"""
    try:
        import torch_xla.core.xla_model as xm
        device = xm.xla_device()
        device_type = 'tpu'
        print(f"ğŸš€ ä½¿ç”¨ TPU v5e-8")
        return device, device_type
    except ImportError:
        if torch.cuda.is_available():
            device = torch.device('cuda')
            device_type = 'gpu'
            gpu_name = torch.cuda.get_device_name(0)
            print(f"ğŸš€ ä½¿ç”¨ GPU: {gpu_name}")
            return device, device_type
        elif torch.backends.mps.is_available():
            device = torch.device('mps')
            device_type = 'gpu'
            print(f"ğŸš€ ä½¿ç”¨ Apple Silicon GPU (MPS)")
            return device, device_type
        else:
            device = torch.device('cpu')
            device_type = 'cpu'
            print("âš ï¸  ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦è¼ƒæ…¢ï¼‰")
            return device, device_type


class RGBFeatureExtractor:
    """RGB ç‰¹å¾µæå–å™¨ - åŸºæ–¼ MobileNetV3"""
    
    def __init__(self, device, device_type):
        self.device = device
        self.device_type = device_type
        
        # è¼‰å…¥ MobileNetV3-Large é è¨“ç·´æ¨¡å‹
        print("ğŸ“¥ è¼‰å…¥ MobileNetV3-Large æ¨¡å‹...")
        try:
            # æ–°ç‰ˆ torchvision (>= 0.13)
            from torchvision.models import MobileNet_V3_Large_Weights
            self.model = models.mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1)
        except (ImportError, AttributeError):
            # èˆŠç‰ˆ torchvision
            self.model = models.mobilenet_v3_large(pretrained=True)
        
        # ç§»é™¤åˆ†é¡å±¤ï¼Œä¿ç•™ç‰¹å¾µæå–éƒ¨åˆ†
        self.model.classifier = nn.Identity()
        
        self.model = self.model.to(device)
        self.model.eval()
        print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
        
        # ImageNet æ¨™æº–åŒ–åƒæ•¸
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        self.batch_size = 32 if device_type == 'tpu' else 16
    
    def load_video(self, video_path, max_frames=300):
        """è®€å–è¦–é »å¹€ï¼Œæœ€å¤š300å¹€"""
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            return None
        
        frames = []
        frame_count = 0
        while frame_count < max_frames:
            ret, frame = cap.read()
            if not ret:
                break
            # è½‰æ›ç‚º RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(frame_rgb)
            frame_count += 1
        
        cap.release()
        return frames
    
    def extract_features_batch(self, frames):
        """æ‰¹æ¬¡æå–ç‰¹å¾µ"""
        all_features = []
        
        # æ‰¹æ¬¡è™•ç†
        for i in range(0, len(frames), self.batch_size):
            batch_frames = frames[i:i + self.batch_size]
            
            # é è™•ç†
            batch_tensors = torch.stack([
                self.transform(frame) for frame in batch_frames
            ]).to(self.device)
            
            # å‰å‘å‚³æ’­
            with torch.no_grad():
                features = self.model(batch_tensors)  # (batch, 960)
            
            all_features.append(features.cpu().numpy())
        
        return np.concatenate(all_features, axis=0)  # (T, 960)
    
    def normalize_rgb_features(self, features):
        """
        æ­£è¦åŒ– RGB ç‰¹å¾µ
        features: (T, 960) - Tå¹€çš„MobileNetV3ç‰¹å¾µ
        """
        # Step 1: L2æ­£è¦åŒ– - æ¯å¹€ç‰¹å¾µå‘é‡å–®ä½åŒ–
        l2_norm = np.linalg.norm(features, axis=1, keepdims=True)
        l2_norm = np.where(l2_norm == 0, 1, l2_norm)  # é¿å…é™¤ä»¥é›¶
        features_l2 = features / l2_norm
        
        # Step 2: æ™‚åºæ¨™æº–åŒ– - æ¸›å»è¦–é »ç´šåˆ¥çš„å‡å€¼å’Œæ¨™æº–å·®
        mean = features_l2.mean(axis=0, keepdims=True)
        std = features_l2.std(axis=0, keepdims=True)
        std = np.where(std == 0, 1, std)  # é¿å…é™¤ä»¥é›¶
        features_normalized = (features_l2 - mean) / std
        
        # Step 3: Clipæ¥µç«¯å€¼ - é™åˆ¶åœ¨[-3, 3]æ¨™æº–å·®ç¯„åœå…§
        features_normalized = np.clip(features_normalized, -3, 3)
        
        return features_normalized
    
    def extract_features_from_frames(self, frames):
        """
        ç›´æ¥å¾ frames æå– RGB ç‰¹å¾µï¼ˆå„ªåŒ–ç‰ˆï¼Œç„¡éœ€è®€å–è¦–é »æ–‡ä»¶ï¼‰
        
        Args:
            frames: list of numpy arrays (H, W, 3) - RGB frames
        
        Returns:
            features: (T, 960) numpy array
        """
        try:
            if frames is None or len(frames) == 0:
                return None
            
            # æ‰¹æ¬¡æå–ç‰¹å¾µ
            features = self.extract_features_batch(frames)
            
            # æ­£è¦åŒ–
            features = self.normalize_rgb_features(features)
            
            return features
        
        except Exception as e:
            print(f"âŒ å¾ frames æå–ç‰¹å¾µå¤±æ•—: {e}")
            return None
    
    def extract_features(self, video_path):
        """æå–å–®å€‹è¦–é »çš„ RGB ç‰¹å¾µ"""
        try:
            # è®€å–è¦–é »
            frames = self.load_video(video_path)
            
            if frames is None or len(frames) == 0:
                return None
            
            # ä½¿ç”¨æ–°æ–¹æ³•æå–ç‰¹å¾µ
            return self.extract_features_from_frames(frames)
        
        except Exception as e:
            print(f"âŒ è™•ç†å¤±æ•— {video_path.name}: {e}")
            return None
    
    def process_directory(self, input_dir, output_dir):
        """è™•ç†æ•´å€‹ç›®éŒ„"""
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True, parents=True)
        
        # ç²å–æ‰€æœ‰å–®è©ç›®éŒ„
        word_dirs = [d for d in input_path.iterdir() if d.is_dir()]
        
        stats = {
            "total_videos": 0,
            "successful": 0,
            "failed": 0,
            "word_details": [],
            "device": self.device_type
        }
        
        print(f"ğŸ“ ç™¼ç¾ {len(word_dirs)} å€‹å–®è©ç›®éŒ„")
        
        # è™•ç†æ¯å€‹å–®è©ç›®éŒ„
        for word_dir in tqdm(word_dirs, desc="è™•ç†å–®è©"):
            word_name = word_dir.name
            word_output_dir = output_path / word_name
            word_output_dir.mkdir(exist_ok=True, parents=True)
            
            # ç²å–æ‰€æœ‰è¦–é »æ–‡ä»¶
            video_files = list(word_dir.glob("*.mp4"))
            word_stats = {"word": word_name, "total": len(video_files), "success": 0, "failed": 0}
            
            for video_file in tqdm(video_files, desc=f"  {word_name}", leave=False):
                stats["total_videos"] += 1
                
                # æå–ç‰¹å¾µ
                features = self.extract_features(video_file)
                
                if features is not None:
                    # ä¿å­˜ .npyï¼ˆæª”åä¸è®Šï¼‰
                    output_file = word_output_dir / f"{video_file.stem}.npy"
                    np.save(output_file, features)
                    stats["successful"] += 1
                    word_stats["success"] += 1
                else:
                    stats["failed"] += 1
                    word_stats["failed"] += 1
            
            stats["word_details"].append(word_stats)
        
        return stats


def create_zip(output_dir, zip_name):
    """æ‰“åŒ…è¼¸å‡ºç›®éŒ„ç‚º ZIP"""
    output_path = Path(output_dir)
    zip_path = output_path.parent / zip_name
    
    print(f"ğŸ“¦ æ‰“åŒ…è¼¸å‡ºæª”æ¡ˆåˆ° {zip_path}...")
    
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file_path in output_path.rglob('*.npy'):
            arcname = file_path.relative_to(output_path.parent)
            zipf.write(file_path, arcname)
    
    zip_size = zip_path.stat().st_size / (1024 * 1024)  # MB
    print(f"âœ… æ‰“åŒ…å®Œæˆï¼ZIP æª”æ¡ˆå¤§å°: {zip_size:.2f} MB")
    return zip_path


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ RGBæµç‰¹å¾µæå– - MobileNetV3")
    print("=" * 60)
    
    # è·¯å¾‘é…ç½®
    kaggle_input = Path("/kaggle/input/original-seg/videos_segmented")
    kaggle_working = Path("/kaggle/working")
    
    if kaggle_input.exists():
        print("ğŸ  æª¢æ¸¬åˆ° Kaggle ç’°å¢ƒ")
        input_dir = kaggle_input
        output_dir = kaggle_working / "rgb_features"
    else:
        print("ğŸ’» æœ¬åœ°ç’°å¢ƒæ¨¡å¼")
        input_dir = Path("/Users/baidongqu/Desktop/SignAR/videos_segmented")
        output_dir = Path("/Users/baidongqu/Desktop/SignAR/rgb_features")
    
    if not input_dir.exists():
        print(f"âŒ è¼¸å…¥ç›®éŒ„ä¸å­˜åœ¨: {input_dir}")
        return
    
    # æª¢æ¸¬è¨­å‚™
    device, device_type = get_device()
    
    # åˆå§‹åŒ–æå–å™¨
    start_time = datetime.now()
    extractor = RGBFeatureExtractor(device, device_type)
    
    # è™•ç†ç›®éŒ„
    stats = extractor.process_directory(input_dir, output_dir)
    
    # æ‰“åŒ… ZIP
    if stats["successful"] > 0:
        zip_path = create_zip(output_dir, "rgb_features.zip")
        stats["zip_path"] = str(zip_path)
    
    # ä¿å­˜å ±å‘Š
    stats["processing_time"] = str(datetime.now() - start_time)
    report_path = output_dir / "extraction_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    # è¼¸å‡ºçµ±è¨ˆ
    print("\n" + "=" * 60)
    print("ğŸ‰ RGBç‰¹å¾µæå–å®Œæˆï¼")
    print(f"ğŸ“Š ç¸½è¦–é »æ•¸: {stats['total_videos']}")
    print(f"âœ… æˆåŠŸ: {stats['successful']}")
    print(f"âŒ å¤±æ•—: {stats['failed']}")
    print(f"â±ï¸  ç¸½è€—æ™‚: {stats['processing_time']}")
    print(f"ğŸ“‹ å ±å‘Š: {report_path}")
    if "zip_path" in stats:
        print(f"ğŸ“¦ ZIP: {stats['zip_path']}")
    print("=" * 60)


if __name__ == "__main__":
    main()

